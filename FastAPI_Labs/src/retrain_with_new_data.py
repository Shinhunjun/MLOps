#!/usr/bin/env python3
"""
ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì¬í›ˆë ¨í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import os
import sys
import json
import glob
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import models
import time

def load_new_data():
    """new_data í´ë”ì—ì„œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¡œë“œ"""
    data_dir = "new_data"
    if not os.path.exists(data_dir):
        print("âŒ new_data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None, None
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì°¾ê¸°
    metadata_files = glob.glob(os.path.join(data_dir, "metadata.json"))
    if not metadata_files:
        print("âŒ metadata.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    with open(metadata_files[0], 'r') as f:
        metadata = json.load(f)
    
    X_new = []
    y_new = []
    
    # ê° ë°ì´í„° í¬ì¸íŠ¸ ì²˜ë¦¬
    for item in metadata:
        image_path = os.path.join(data_dir, item['filename'])
        if os.path.exists(image_path):
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
                image = Image.open(image_path).convert('L')
                image = image.resize((28, 28))
                pixels = np.array(image).flatten() / 255.0
                
                X_new.append(pixels)
                y_new.append(item['true_label'])
                
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {image_path} - {e}")
                continue
    
    if len(X_new) == 0:
        print("âŒ ìœ íš¨í•œ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    print(f"âœ… {len(X_new)}ê°œì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    return np.array(X_new), np.array(y_new)

def load_original_data():
    """ê¸°ì¡´ MNIST ë°ì´í„° ë¡œë“œ"""
    from data import load_data
    X, y = load_data()
    return X, y


def retrain_cnn(X_original, y_original, X_new, y_new):
    """CNN ëª¨ë¸ ì¬í›ˆë ¨"""
    print("ğŸ”„ CNN ëª¨ë¸ ì¬í›ˆë ¨ ì¤‘...")
    
    # ìƒˆë¡œìš´ ë°ì´í„°ì— ì¦ê°• ì ìš©
    print(f"ğŸ”„ ìƒˆë¡œìš´ ë°ì´í„° ì¦ê°• ì¤‘... (ì¦ê°• ë°°ìˆ˜: 3)")
    try:
        from augmentation import augment_dataset
        X_new_augmented, y_new_augmented = augment_dataset(X_new, y_new, 3)
        print(f"âœ… ë°ì´í„° ì¦ê°• ì™„ë£Œ: {len(X_new)}ê°œ â†’ {len(X_new_augmented)}ê°œ")
    except ImportError:
        print("âš ï¸ augmentation ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¦ê°• ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        X_new_augmented, y_new_augmented = X_new, y_new
    except Exception as e:
        print(f"âš ï¸ ë°ì´í„° ì¦ê°• ì‹¤íŒ¨: {e}. ì›ë³¸ ë°ì´í„°ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        X_new_augmented, y_new_augmented = X_new, y_new
    
    # ê¸°ì¡´ ë°ì´í„°ì™€ ì¦ê°•ëœ ìƒˆë¡œìš´ ë°ì´í„° ê²°í•©
    X_combined = np.vstack([X_original, X_new_augmented])
    y_combined = np.hstack([y_original, y_new_augmented])
    
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X_combined, y_combined, test_size=0.2, random_state=42
    )
    
    # í›ˆë ¨ ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ ê²€ì¦ ì„¸íŠ¸ë¡œ ë‹¤ì‹œ ë¶„í• 
    X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )
    
    # CNN ëª¨ë¸ ë¡œë“œ (ê¸°ì¡´ ëª¨ë¸)
    try:
        cnn_model = models.load_model("model/cnn_mnist_model.h5")
        print("âœ… ê¸°ì¡´ CNN ëª¨ë¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except:
        print("âš ï¸ ê¸°ì¡´ CNN ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        from cnn_model import create_cnn_model
        cnn_model = create_cnn_model()
    
    # ë°ì´í„° í˜•íƒœ ë³€í™˜ (28, 28, 1)
    X_train_cnn = X_train_cnn.reshape(-1, 28, 28, 1)
    X_val_cnn = X_val_cnn.reshape(-1, 28, 28, 1)
    X_test_cnn = X_test.reshape(-1, 28, 28, 1)
    
    # ëª¨ë¸ ì¬í›ˆë ¨ (fine-tuning)
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
    
    callbacks = [
        EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)
    ]
    
    start_time = time.time()
    history = cnn_model.fit(
        X_train_cnn, y_train_cnn,
        validation_data=(X_val_cnn, y_val_cnn),
        epochs=10,  # ì ì€ ì—í¬í¬ë¡œ fine-tuning
        batch_size=64,
        callbacks=callbacks,
        verbose=1
    )
    training_time = time.time() - start_time
    
    # ì •í™•ë„ í‰ê°€
    test_loss, test_accuracy = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)
    print(f"âœ… CNN ì¬í›ˆë ¨ ì™„ë£Œ! ì •í™•ë„: {test_accuracy:.4f}, ì‹œê°„: {training_time:.2f}ì´ˆ")
    
    # ëª¨ë¸ ì €ì¥
    cnn_model.save("model/cnn_mnist_model.h5")
    print("ğŸ’¾ CNN ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return cnn_model

def archive_used_data():
    """ì‚¬ìš©ëœ ë°ì´í„°ë¥¼ ì•„ì¹´ì´ë¸Œ í´ë”ë¡œ ì´ë™"""
    data_dir = "new_data"
    archive_dir = "archived_data"
    
    os.makedirs(archive_dir, exist_ok=True)
    
    # í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì•„ì¹´ì´ë¸Œ í´ë” ìƒì„±
    timestamp = int(time.time())
    archive_subdir = os.path.join(archive_dir, f"batch_{timestamp}")
    os.makedirs(archive_subdir, exist_ok=True)
    
    # íŒŒì¼ë“¤ ì´ë™
    for filename in os.listdir(data_dir):
        if filename.endswith(('.png', '.jpg', '.jpeg', '.json')):
            src = os.path.join(data_dir, filename)
            dst = os.path.join(archive_subdir, filename)
            os.rename(src, dst)
    
    print(f"ğŸ“ ì‚¬ìš©ëœ ë°ì´í„°ê°€ {archive_subdir}ë¡œ ì•„ì¹´ì´ë¸Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ëª¨ë¸ ì¬í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ìƒˆë¡œìš´ ë°ì´í„° ë¡œë“œ
    X_new, y_new = load_new_data()
    if X_new is None:
        print("âŒ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š ê¸°ì¡´ MNIST ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘...")
    X_original, y_original = load_original_data()
    
    print(f"ğŸ“ˆ ë°ì´í„° í†µê³„:")
    print(f"  - ê¸°ì¡´ ë°ì´í„°: {len(X_original)}ê°œ")
    print(f"  - ìƒˆë¡œìš´ ë°ì´í„°: {len(X_new)}ê°œ")
    print(f"  - ì´ ë°ì´í„°: {len(X_original) + len(X_new)}ê°œ")
    
    # ëª¨ë¸ ì¬í›ˆë ¨
    try:
        # CNN ì¬í›ˆë ¨
        retrain_cnn(X_original, y_original, X_new, y_new)
        
        # ì‚¬ìš©ëœ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
        archive_used_data()
        
        print("ğŸ‰ CNN ëª¨ë¸ ì¬í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"âŒ ì¬í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
